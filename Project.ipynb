{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZYzJLxnmdc6"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N04C5A9emdc8"
   },
   "source": [
    "First, let's make sure we have the proper version installed. This notebook works in python 3. Import a few common modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uq0DkO1jmddC"
   },
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL_39lVTmddB"
   },
   "outputs": [],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                # For operating system dependent functionality\n",
    "import cv2                               # OpenCV library for image processing\n",
    "import gc                                # Garbage collector for memory management\n",
    "import torch                             # PyTorch deep learning framework\n",
    "import numpy as np                       # NumPy for numerical computations\n",
    "import motmetrics as mm                  # Metrics for multiple object tracking\n",
    "\n",
    "import matplotlib                        # Matplotlib for data visualization\n",
    "import matplotlib.pyplot as plt          # Plotting graphs and figures\n",
    "\n",
    "import tensorflow as tf                  # TensorFlow deep learning framework\n",
    "import tensorflow_datasets as tfds       # TensorFlow Datasets library\n",
    "import flow_vis                          # Optical flow visualization\n",
    "from flow_util import *                  # Flow utilities\n",
    "import matplotlib.patches as patches     # For drawing shapes on plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkg_resources import parse_version  # Importing version parsing from package resources\n",
    "from PIL import Image                    # Importing Image module from the Python Imaging Library (PIL)\n",
    "\n",
    "# Python â‰¥3.5 is required\n",
    "import sys                               # Importing system-related functionalities\n",
    "assert sys.version_info >= (3,5)         # Assertion to check if the Python version is 3.5 or higher\n",
    "\n",
    "from google.colab import drive           # Importing Google Colab drive functionalities\n",
    "from ultralytics import YOLO             # Importing YOLO object detection module from Ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a set of utility functions related to setting up the environment, saving figures, and generating log directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOBK44-Gmdc8",
    "outputId": "a0a5719d-ec49-4b0e-805f-cd4970445403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running on CoLab\n"
     ]
    }
   ],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "# Based on post by GM at https://stackoverflow.com/questions/53581278\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on CoLab')\n",
    "  from google.colab import drive\n",
    "  # mount your google drive into colab\n",
    "  # this is interactive unfortunately\n",
    "  # must paste authorization code on prompt\n",
    "  drive.mount('/content/drive')\n",
    "  PROJECT_ROOT_DIR = \"drive/MyDrive/Colab Notebooks\"\n",
    "else:\n",
    "  print('Not running on CoLab')\n",
    "  PROJECT_ROOT_DIR = os.getcwd()\n",
    "\n",
    "NB_ID = \"project\"\n",
    "\n",
    "# create the directory if it does not exist\n",
    "IMAGE_DIR = os.path.join(PROJECT_ROOT_DIR, \"images\", NB_ID)\n",
    "os.makedirs(IMAGE_DIR, exist_ok = True)\n",
    "\n",
    "def save_fig_nb(fig_id, tight_layout=True):\n",
    "    path = os.path.join(IMAGE_DIR, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "os.makedirs(os.path.join(PROJECT_ROOT_DIR,\"tb_logs\",NB_ID), exist_ok = True)\n",
    "\n",
    "def get_logdir(add=''):\n",
    "    import time\n",
    "    log_id = time.strftime(\"log_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(PROJECT_ROOT_DIR,\"tb_logs\",NB_ID,log_id+add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdkbKDx9mdc-"
   },
   "source": [
    "A couple utility functions to plot grayscale and RGB images (source Aurelien Geron):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAfAaCoumdc-"
   },
   "outputs": [],
   "source": [
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"gray\", interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def plot_color_image(image):\n",
    "    plt.imshow(image.astype(np.uint8),interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TNcEogwmdc-"
   },
   "source": [
    "## Import tfds and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYihM5JSmdc-",
    "outputId": "5e8f92b3-3dd0-4a68-e6eb-90574bf07404"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 23:33:48.457661: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 23:33:48.487209: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 23:33:48.487656: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 23:33:49.005772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/luminatech/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 23:33:49.887974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-30 23:33:49.913627: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# For some reason we seem to need to load tf onto the GPU first\n",
    "dummy = tf.constant( 32 )\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFJ9jaq9mdc_"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "The dataset is packaged as a Tensorflow dataset in three sub categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyshjJcVmdc_",
    "outputId": "052eae81-cac1-43a9-a36f-ebba11ae32c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training\n"
     ]
    }
   ],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "print(PROJECT_ROOT_DIR)\n",
    "\n",
    "data_path = os.path.join(PROJECT_ROOT_DIR, 'tensorflow_data')\n",
    "os.makedirs(data_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iAyfVBZmdc_"
   },
   "source": [
    "# YoloV8 dataset\n",
    "\n",
    "## Images dataset\n",
    "Exporting images from tfrecords and splitting into train, validation, and test datasets in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gcza4Zxwmdc_",
    "outputId": "3a983b4b-8a35-4835-9f8b-fd04c3b648f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint16'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint16.\n",
      "WARNING:absl:You use TensorFlow DType <dtype: 'uint8'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to uint8.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directory:  /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/tensorflow_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n",
      "WARNING:absl:`FeatureConnector.dtype` is deprecated. Please change your code to use NumPy with the field `FeatureConnector.np_dtype` or use TensorFlow with the field `FeatureConnector.tf_dtype`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos in fixed_random_rotate: 30\n",
      "Total videos in linear_movement_rotate: 30\n",
      "Total videos in rotation_rotate: 30\n",
      "Total images in train folder: 1440\n",
      "Total images in val folder: 180\n",
      "Total images in test folder: 540\n"
     ]
    }
   ],
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "print(\"Using directory: \", data_path)\n",
    "\n",
    "# Dataset names for each fold\n",
    "fold_names = ['fixed_random_rotate', 'linear_movement_rotate', 'rotation_rotate']\n",
    "\n",
    "# Create a dictionary to store the datasets for each fold\n",
    "fold_datasets = {}\n",
    "\n",
    "for fold_name in fold_names:\n",
    "    # Load the dataset for the current fold\n",
    "    dataset = tfds.load(f'elg7186_projectdata/{fold_name}', data_dir=data_path)\n",
    "    fold_datasets[fold_name] = dataset\n",
    "\n",
    "# Create a list to store all images in the fold\n",
    "images_train = []\n",
    "images_val = []\n",
    "images_test = []\n",
    "\n",
    "# Access images from each fold\n",
    "for fold_name, dataset in fold_datasets.items():\n",
    "\n",
    "    # Iterate over all examples in the fold\n",
    "    vid_num = 0\n",
    "    for example in dataset['train']:\n",
    "        # Get the video from the example\n",
    "        video = example['video']\n",
    "\n",
    "        # Iterate over all frames in the video and add them to the list\n",
    "        frame_num = 0\n",
    "        for frame in video:\n",
    "            if frame_num <16:\n",
    "                images_train.append(frame.numpy())\n",
    "                img = Image.fromarray(frame.numpy())\n",
    "                img.save(f'./datasets/data/train/images/{fold_name}_video_{vid_num}_frame_{frame_num}.png')\n",
    "            elif frame_num<18 :\n",
    "                images_val.append(frame.numpy())\n",
    "                img = Image.fromarray(frame.numpy())\n",
    "                img.save(f'./datasets/data/val/images/{fold_name}_video_{vid_num}_frame_{frame_num}.png')\n",
    "            else:\n",
    "                images_test.append(frame.numpy())\n",
    "                img = Image.fromarray(frame.numpy())\n",
    "                img.save(f'./datasets/data/test/images/{fold_name}_video_{vid_num}_frame_{frame_num}.png')\n",
    "\n",
    "            frame_num+=1\n",
    "        vid_num += 1\n",
    "    print(f\"Total videos in {fold_name}: {len(dataset['train'])}\")\n",
    "\n",
    "print(f\"Total images in train folder: {len(images_train)}\")\n",
    "print(f\"Total images in val folder: {len(images_val)}\")\n",
    "print(f\"Total images in test folder: {len(images_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a75LcQY5mddA"
   },
   "source": [
    "## Labels dataset\n",
    "Exporting labels from tfrecords and splitting into train, validation, and test datasets in different folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmHf1WUPmddA",
    "outputId": "b411ccf2-dea3-4cf6-f917-32017bb79184"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video:  0003\n",
      "Video type:  fixed_random_rotate_007\n",
      "forward_flow range -16.59033203125 to 16.885251998901367\n",
      "resolution: [<tf.Tensor: shape=(), dtype=int32, numpy=256>, <tf.Tensor: shape=(), dtype=int32, numpy=256>]\n",
      "\n",
      "\n",
      "Video:  0006\n",
      "Video type:  fixed_random_rotate_003\n",
      "forward_flow range -15.715254783630371 to 53.34239959716797\n",
      "resolution: [<tf.Tensor: shape=(), dtype=int32, numpy=256>, <tf.Tensor: shape=(), dtype=int32, numpy=256>]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Video:  0001\n",
      "Video type:  fixed_random_rotate_003\n",
      "forward_flow range -13.709030151367188 to 19.553253173828125\n",
      "resolution: [<tf.Tensor: shape=(), dtype=int32, numpy=256>, <tf.Tensor: shape=(), dtype=int32, numpy=256>]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/trainin_testing.ipynb Cell 13\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#Y101sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m rect \u001b[39m=\u001b[39m patches\u001b[39m.\u001b[39mRectangle((x_min, y_min), x_max \u001b[39m-\u001b[39m x_min, y_max \u001b[39m-\u001b[39m y_min, linewidth\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#Y101sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m<\u001b[39m\u001b[39m16\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#Y101sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(x_max\u001b[39m-\u001b[39mx_min)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39mx_min\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(y_max\u001b[39m-\u001b[39my_min)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39my_min\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(x_max\u001b[39m-\u001b[39mx_min)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(y_max\u001b[39m-\u001b[39my_min)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#Y101sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39melif\u001b[39;00m i\u001b[39m<\u001b[39m\u001b[39m18\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#Y101sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     g\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(x_max\u001b[39m-\u001b[39mx_min)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39mx_min\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(y_max\u001b[39m-\u001b[39my_min)\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39my_min\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(x_max\u001b[39m-\u001b[39mx_min)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m(y_max\u001b[39m-\u001b[39my_min)\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def find_index(input, id):\n",
    "    # Function to find the index of 'id' in 'input'\n",
    "    for i in range(len(input)):\n",
    "        if input[i] == id:\n",
    "            return i\n",
    "            break\n",
    "\n",
    "gt_mot = []\n",
    "\n",
    "# Iterate through the 'fold_datasets' dictionary\n",
    "for fold_name, dataset in fold_datasets.items():\n",
    "    # Iterate through the 'train' dataset within each 'fold_name'\n",
    "    vid_num = 0\n",
    "    for example in dataset['train']:\n",
    "        # Extract video name and type from example metadata\n",
    "        video_name, video_type = get_video_names(example['metadata'])\n",
    "\n",
    "        # Extract scale and offset from example metadata\n",
    "        f_scale, f_offset = get_scale_offset(example['metadata'])\n",
    "\n",
    "        # Extract number of frames and resolution from example metadata\n",
    "        num_frames = int(example['metadata']['num_frames'])\n",
    "        resolution = [example['metadata']['height'], example['metadata']['width']]\n",
    "\n",
    "        # Print resolution\n",
    "        print('resolution:', resolution)\n",
    "\n",
    "        # Initialize arrays for x_mesh and y_mesh\n",
    "        x_mesh = np.empty(1)\n",
    "        y_mesh = np.empty(1)\n",
    "\n",
    "        trk_id= dict()\n",
    "        trk_num = 0\n",
    "\n",
    "        dict_1 = {}\n",
    "\n",
    "        # Loop through each frame in the video\n",
    "        for i in range(num_frames):\n",
    "\n",
    "            # Get the image for the current frame\n",
    "            image = example['video'][i, :, :, :]\n",
    "\n",
    "            # Create a subplot for the boundimg boxes\n",
    "            segmentation = example['segmentations'][i, :, :, :].numpy()\n",
    "\n",
    "            if i<16:\n",
    "                f= open(f\"./datasets/data/train/labels/{fold_name}_video_{vid_num}_frame_{i}.txt\",\"w+\")\n",
    "            elif i<18:\n",
    "                g= open(f\"./datasets/data/val/labels/{fold_name}_video_{vid_num}_frame_{i}.txt\",\"w+\")\n",
    "            else:\n",
    "                h= open(f\"./datasets/data/test/labels/{fold_name}_video_{vid_num}_frame_{i}.txt\",\"w+\")\n",
    "            # Loop through the instances in the frame\n",
    "\n",
    "            dict_2 = {}\n",
    "            min_dist = 0\n",
    "            for id in range(example['instances']['bbox_frames'].shape[0]):\n",
    "                if i in example['instances']['bbox_frames'][id]:\n",
    "                    t = find_index(example['instances']['bbox_frames'][id], i)\n",
    "                    item = example['instances']['bboxes'][id, t, :]\n",
    "                    cls_id = example['instances']['category'][id]\n",
    "                    cls_name = example['instances']['asset_id'][id]\n",
    "                    y_min = int(item[0] * float(resolution[0]))/example['metadata']['height']\n",
    "                    x_min = int(item[1] * float(resolution[1]))/example['metadata']['width']\n",
    "                    y_max = int(item[2] * float(resolution[0]))/example['metadata']['height']\n",
    "                    x_max = int(item[3] * float(resolution[1]))/example['metadata']['width']\n",
    "\n",
    "                    if id < 1:\n",
    "                        if trk_num not in dict_1:\n",
    "                            dict_1[trk_num] = (x_min,y_min,(x_max-x_min),(y_max-y_min))\n",
    "                    else:\n",
    "                        for key, value in dict_1:\n",
    "                            if abs(value - (x_min,y_min)) < min_dist:\n",
    "                                min_dist = abs(value - (x_min,y_min))\n",
    "                                min_key = key\n",
    "                        dict_2[min_key] = (x_min,y_min)\n",
    "                        dict_1 = {}\n",
    "                        for key, value in dict_2:\n",
    "                            dict_1[key] = value\n",
    "\n",
    "                    for key, value in dict_1:\n",
    "                        gt_mot.append([i, key, x_min, y_min, (x_max-x_min), (y_max-y_min)])\n",
    "\n",
    "\n",
    "                    # Create a Rectangle patch for bounding box\n",
    "                    rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "                    if i<16:\n",
    "                        f.write(f\"{id} {(x_max-x_min)/2 + x_min} {(y_max-y_min)/2 + y_min} {(x_max-x_min)} {(y_max-y_min)}\\n\")\n",
    "                    elif i<18:\n",
    "                        g.write(f\"{id} {(x_max-x_min)/2 + x_min} {(y_max-y_min)/2 + y_min} {(x_max-x_min)} {(y_max-y_min)}\\n\")\n",
    "                    else:\n",
    "                        h.write(f\"{id} {(x_max-x_min)/2 + x_min} {(y_max-y_min)/2 + y_min} {(x_max-x_min)} {(y_max-y_min)}\\n\")\n",
    "                    trk_num += 1\n",
    "                else:\n",
    "                    print(\"\")  # empty line\n",
    "        vid_num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cju80a_bmddA"
   },
   "source": [
    "# Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eRhIcdWmddB"
   },
   "source": [
    "### Initializing YOLOv8 Model with Ultralytics Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjP4lX0lmddB",
    "outputId": "6f2ff3bc-024e-4d66-a788-1b68631064ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ Ultralytics settings reset to default values. This may be due to a possible problem with your settings or a recent ultralytics package update. \n",
      "View settings with 'yolo settings' or at '/home/luminatech/.config/Ultralytics/settings.yaml'\n",
      "Update settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'.\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "model = YOLO(\"yolov8x.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y72p34O1mddB"
   },
   "source": [
    "### Training YOLOv8 Model on the Kubric Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JswIpgH0mddB"
   },
   "outputs": [],
   "source": [
    "model.train(data = \"data.yaml\", epochs = 1, batch = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0Ge_V9rmddB"
   },
   "source": [
    "### Image Loading Function with OpenCV: Load Images from Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMrLujuMmddB"
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Load images from a specified folder.\n",
    "\n",
    "    Parameters:\n",
    "    - folder (str): Path to the folder containing images.\n",
    "\n",
    "    Returns:\n",
    "    - images (list): List of images loaded from the folder.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "\n",
    "    # Iterate through each file in the folder\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "\n",
    "        # Check if the image is not None (i.e., if it was successfully loaded)\n",
    "        if img is not None:\n",
    "            # Append the loaded image to the list\n",
    "            images.append(img)\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdl4nA8_mddB"
   },
   "source": [
    "Downloading Tracker Configuration Files: bytetrack.yaml and botsort.yaml from Ultralytics Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0elebdjBmddB"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/trackers/bytetrack.yaml\n",
    "!wget https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/trackers/botsort.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIArCEBsmddC"
   },
   "source": [
    "YOLOv8 Object Tracking and Visualization: Using bytetrack and botsort Trackers on Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoZRwXd_mddC"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs object tracking using the YOLOv8 model for each image in a specified dataset folder. It utilizes two different trackers ('bytetrack' and 'botsort') provided as YAML configuration files. The annotations obtained from the tracking are stored in lists and then used to create two separate annotated video outputs using OpenCV's VideoWriter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k2CJdXX8mddC"
   },
   "outputs": [],
   "source": [
    "# Load images from the specified folder\n",
    "images = load_images_from_folder('./datasets/data/test/images')\n",
    "\n",
    "# Initialize YOLOv8 model with a specified checkpoint\n",
    "model = YOLO(\"runs/detect/train14/weights/best.pt\")\n",
    "\n",
    "# Lists to store annotated frames for each tracker\n",
    "video_byte = []\n",
    "video_bot = []\n",
    "\n",
    "# Loop through each image in the dataset\n",
    "for image in images:\n",
    "    # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "    results_byte = model.track(image, persist=True, save=True, save_crop=True, project=\"runs/detect\", name=\"inference\", exist_ok=True, tracker='bytetrack.yaml')\n",
    "    results_bot = model.track(image, persist=True, save=True, save_crop=True, project=\"runs/detect\", name=\"inference\", exist_ok=True, tracker='botsort.yaml')\n",
    "\n",
    "    # Visualize the results on the frame\n",
    "    annotated_frame_byte = results_byte[0].plot()\n",
    "    annotated_frame_bot = results_bot[0].plot()\n",
    "\n",
    "    # Append annotated frames to the respective lists\n",
    "    video_byte.append(annotated_frame_byte)\n",
    "    video_bot.append(annotated_frame_bot)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow(\"YOLOv8 Tracking using bytetrack tracker\", annotated_frame_byte)\n",
    "    cv2.imshow(\"YOLOv8 Tracking using botsort tracker\", annotated_frame_bot)\n",
    "\n",
    "# Create video writers for the output videos\n",
    "out_byte = cv2.VideoWriter('project_byte.avi', cv2.VideoWriter_fourcc(*'DIVX'), 8, (256, 256))\n",
    "out_bot = cv2.VideoWriter('project_bot.avi', cv2.VideoWriter_fourcc(*'DIVX'), 8, (256, 256))\n",
    "\n",
    "# Write annotated frames to the output videos\n",
    "for i in range(len(video_byte)):\n",
    "    out_byte.write(video_byte[i])\n",
    "    out_bot.write(video_bot[i])\n",
    "\n",
    "# Release the video writers\n",
    "out_byte.release()\n",
    "out_bot.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkMkzXizmddC"
   },
   "source": [
    "We're using a library to figure out two important things: how accurate the tracking is (MOTA) and how precise it is (MOTP). The tricky part was getting our hands on the right data format. We had to make sure the labels that tell us where the objects are in the real world and where our model thinks they are match up in a way the library understands. It took some careful preparation to get the data in the right shape. Despite the challenges, our goal is to give a clear picture of how well the tracking model does in real-life situations, showing how close it gets to the right answer and how exact its guesses are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBgSfGBwmddD"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRILr6SqmddD"
   },
   "source": [
    "# Training: record performance\n",
    "starting at train 72 - 89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs hyperparameter tuning and training of YOLOv8 models with various combinations of hyperparameters. It utilizes nested loops to iterate through different combinations of models, epochs, batch sizes, learning rates, and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn4w1uwVmddD",
    "outputId": "9c9229f3-854e-4c0d-d580-528e65bffb76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train72, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train72\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train72', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train72/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train72\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.98G     0.9345      2.467      1.299         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.28it/s]\n",
      "                   all        540       1728      0.655      0.236      0.233      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.02G     0.9779      2.179      1.364          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.24it/s]\n",
      "                   all        540       1728      0.376      0.228      0.194      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.99G     0.9394      1.964      1.332         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.24it/s]\n",
      "                   all        540       1728      0.517      0.248       0.21      0.167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.02G     0.8422      1.779      1.257          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.23it/s]\n",
      "                   all        540       1728      0.715      0.257      0.298      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.99G     0.8117      1.642      1.232          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.21it/s]\n",
      "                   all        540       1728      0.368      0.391      0.337      0.284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.99G     0.7382      1.483       1.18          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.15it/s]\n",
      "                   all        540       1728      0.579      0.348      0.381      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.02G     0.6677      1.317      1.126          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.05it/s]\n",
      "                   all        540       1728       0.68      0.466      0.438      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.99G     0.6221      1.192      1.094          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.11it/s]\n",
      "                   all        540       1728      0.628      0.445      0.484      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.99G     0.5821       1.08      1.064         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:37<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.09it/s]\n",
      "                   all        540       1728      0.461      0.542      0.541      0.489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.01G     0.5359     0.9348      1.033          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.12it/s]\n",
      "                   all        540       1728      0.606       0.53      0.588      0.532\n",
      "\n",
      "10 epochs completed in 0.322 hours.\n",
      "Optimizer stripped from runs/detect/train72/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train72/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train72/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.33it/s]\n",
      "                   all        540       1728      0.606       0.53      0.588      0.532\n",
      "        Action Figures        540         38      0.417      0.895       0.77      0.686\n",
      "                   Bag        540         54      0.526      0.778      0.779      0.754\n",
      "Bottles and Cans and Cups        540         40     0.0928      0.025     0.0898     0.0853\n",
      "        Consumer Goods        540        457      0.713      0.794      0.846      0.787\n",
      "              Keyboard        540         15          1          0     0.0368      0.023\n",
      "                 Legos        540         12          1      0.371      0.852      0.726\n",
      "           Media Cases        540         18      0.605      0.222      0.272      0.269\n",
      "                 Mouse        540         12      0.474        0.5      0.558      0.463\n",
      "                  None        540        374      0.564      0.741      0.714      0.672\n",
      "                  Shoe        540        495      0.761      0.806      0.839      0.745\n",
      "                  Toys        540        213      0.515        0.7      0.713      0.641\n",
      "Speed: 0.2ms preprocess, 20.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train72\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.001, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train73, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train73\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train73', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train73/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train73\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.73G     0.6491      3.541      1.111         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.02it/s]\n",
      "                   all        540       1728      0.179      0.252      0.184      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.72G     0.5197      2.133      1.029          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.08it/s]\n",
      "                   all        540       1728      0.668      0.409      0.414      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.72G     0.4529      1.616     0.9804         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.00it/s]\n",
      "                   all        540       1728      0.846      0.428      0.524      0.497\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      2.72G     0.4014      1.156     0.9372          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.26it/s]\n",
      "                   all        540       1728      0.629       0.63      0.727      0.693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.75G     0.3821     0.8865     0.9163          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.05it/s]\n",
      "                   all        540       1728      0.864      0.672      0.792      0.744\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.75G     0.3575     0.7032     0.8954          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.06it/s]\n",
      "                   all        540       1728      0.852      0.737      0.839      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.75G     0.3415     0.5907     0.8885          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.08it/s]\n",
      "                   all        540       1728      0.848      0.822       0.88      0.831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.75G     0.3327      0.527     0.8758          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.12it/s]\n",
      "                   all        540       1728       0.94      0.803      0.884      0.832\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.74G     0.3292     0.4833     0.8748         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.21it/s]\n",
      "                   all        540       1728      0.932       0.81      0.906      0.852\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.75G     0.3247       0.45     0.8679          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.26it/s]\n",
      "                   all        540       1728       0.91      0.846      0.907      0.856\n",
      "\n",
      "10 epochs completed in 0.337 hours.\n",
      "Optimizer stripped from runs/detect/train73/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train73/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train73/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.69it/s]\n",
      "                   all        540       1728       0.91      0.846      0.908      0.857\n",
      "        Action Figures        540         38      0.834      0.974      0.991      0.975\n",
      "                   Bag        540         54      0.949      0.926      0.975      0.962\n",
      "Bottles and Cans and Cups        540         40      0.906       0.75      0.812      0.797\n",
      "        Consumer Goods        540        457      0.909      0.917      0.966      0.935\n",
      "              Keyboard        540         15          1      0.316      0.587      0.393\n",
      "                 Legos        540         12      0.815          1      0.995      0.909\n",
      "           Media Cases        540         18      0.945      0.833      0.894      0.803\n",
      "                 Mouse        540         12      0.927          1      0.995      0.995\n",
      "                  None        540        374      0.887      0.832      0.901      0.858\n",
      "                  Shoe        540        495      0.956      0.881      0.948      0.908\n",
      "                  Toys        540        213      0.882      0.873      0.928      0.891\n",
      "Speed: 0.2ms preprocess, 20.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train73\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.001, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train74, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train74\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train74', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train74/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train74\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      3.01G      3.281      3.961      3.224         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:38<00:00,  7.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:14<00:00,  9.17it/s]\n",
      "                   all        540       1728    0.00131      0.116    0.00184   0.000461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.03G      2.901      3.502      2.817          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.02it/s]\n",
      "                   all        540       1728       0.46     0.0239    0.00744    0.00253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.01G      2.711      3.412      2.673         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.45it/s]\n",
      "                   all        540       1728    0.00317      0.187     0.0088    0.00253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.03G      2.619      3.342       2.59          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.26it/s]\n",
      "                   all        540       1728    0.00445      0.169    0.00559    0.00192\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.04G      2.563      3.298      2.566          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.81it/s]\n",
      "                   all        540       1728      0.479     0.0102     0.0111    0.00337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      3.02G      2.439      3.199      2.446          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.31it/s]\n",
      "                   all        540       1728    0.00974      0.175     0.0101    0.00406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.02G      2.379      3.158      2.392          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.99it/s]\n",
      "                   all        540       1728      0.284     0.0131     0.0103     0.0032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.05G      2.325      3.053      2.358          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.13it/s]\n",
      "                   all        540       1728      0.741     0.0183    0.00852    0.00346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      3.04G      2.231      2.971      2.284         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.17it/s]\n",
      "                   all        540       1728    0.00825      0.122     0.0114    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.02G      2.217      2.928      2.258          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.17it/s]\n",
      "                   all        540       1728      0.484     0.0279     0.0149    0.00545\n",
      "\n",
      "10 epochs completed in 0.323 hours.\n",
      "Optimizer stripped from runs/detect/train74/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train74/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train74/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.76it/s]\n",
      "                   all        540       1728      0.484     0.0278     0.0151    0.00549\n",
      "        Action Figures        540         38          0          0    0.00724    0.00272\n",
      "                   Bag        540         54          1          0      0.044     0.0169\n",
      "Bottles and Cans and Cups        540         40          1          0          0          0\n",
      "        Consumer Goods        540        457     0.0867     0.0678     0.0329      0.013\n",
      "              Keyboard        540         15          0          0          0          0\n",
      "                 Legos        540         12          1          0          0          0\n",
      "           Media Cases        540         18          1          0          0          0\n",
      "                 Mouse        540         12          1          0          0          0\n",
      "                  None        540        374     0.0741      0.147      0.032     0.0123\n",
      "                  Shoe        540        495      0.101     0.0586     0.0328     0.0107\n",
      "                  Toys        540        213     0.0638     0.0329     0.0167    0.00471\n",
      "Speed: 0.2ms preprocess, 20.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train74\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.001, optimizer: RMSProp\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train75, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train75\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train75', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train75/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train75\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      3.05G      1.959      3.507      2.215         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:40<00:00,  7.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.10it/s]\n",
      "                   all        540       1728      0.305      0.026     0.0123    0.00776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.04G      1.681      2.983      1.968          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.12it/s]\n",
      "                   all        540       1728      0.433     0.0751     0.0641     0.0411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.05G      1.534      2.767      1.831         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.24it/s]\n",
      "                   all        540       1728      0.561      0.135     0.0723     0.0473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.06G      1.435      2.638      1.743          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.20it/s]\n",
      "                   all        540       1728      0.549      0.158     0.0789     0.0539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.03G      1.336      2.534      1.658          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.15it/s]\n",
      "                   all        540       1728      0.535      0.158     0.0807     0.0548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      3.06G      1.249      2.381      1.582          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.22it/s]\n",
      "                   all        540       1728      0.614      0.145      0.111     0.0693\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.06G      1.197      2.291      1.542          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.30it/s]\n",
      "                   all        540       1728      0.732      0.121     0.0987     0.0698\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.05G      1.123       2.22      1.485          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.20it/s]\n",
      "                   all        540       1728      0.723      0.194      0.115     0.0851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      3.06G      1.045      2.076      1.429         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.07it/s]\n",
      "                   all        540       1728      0.605      0.194      0.139      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.06G       1.01      2.004      1.387          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.26it/s]\n",
      "                   all        540       1728       0.37      0.259      0.155      0.114\n",
      "\n",
      "10 epochs completed in 0.339 hours.\n",
      "Optimizer stripped from runs/detect/train75/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train75/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train75/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.72it/s]\n",
      "                   all        540       1728      0.371      0.261      0.155      0.113\n",
      "        Action Figures        540         38      0.125      0.447      0.133      0.105\n",
      "                   Bag        540         54       0.16      0.222      0.165      0.148\n",
      "Bottles and Cans and Cups        540         40     0.0123      0.025     0.0118    0.00935\n",
      "        Consumer Goods        540        457      0.239      0.678      0.324       0.26\n",
      "              Keyboard        540         15          1          0          0          0\n",
      "                 Legos        540         12          1          0     0.0563     0.0366\n",
      "           Media Cases        540         18          0          0    0.00723    0.00591\n",
      "                 Mouse        540         12          1          0      0.244      0.113\n",
      "                  None        540        374      0.228      0.578       0.27      0.215\n",
      "                  Shoe        540        495      0.212       0.61       0.33       0.26\n",
      "                  Toys        540        213      0.109      0.315      0.166     0.0938\n",
      "Speed: 0.2ms preprocess, 19.8ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train75\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.01, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train76, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train76\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train76', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train76/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train76\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.76G     0.5641      2.466      1.048         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:38<00:00,  7.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.28it/s]\n",
      "                   all        540       1728      0.703      0.459      0.512      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.76G     0.4627      1.269     0.9699          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.27it/s]\n",
      "                   all        540       1728      0.652      0.637      0.654      0.598\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.77G     0.4953      1.064     0.9805         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.23it/s]\n",
      "                   all        540       1728      0.812      0.628      0.693      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      2.76G     0.5248     0.9513     0.9928          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.25it/s]\n",
      "                   all        540       1728      0.703      0.704      0.743      0.672\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.76G      0.531     0.8971     0.9891          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.03it/s]\n",
      "                   all        540       1728      0.865      0.656      0.748      0.678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.76G     0.5129     0.7282     0.9731          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.02it/s]\n",
      "                   all        540       1728      0.815      0.724      0.819      0.708\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.73G     0.4896     0.6202     0.9607          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.16it/s]\n",
      "                   all        540       1728      0.862      0.683      0.793      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.76G     0.4593     0.5376     0.9387          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.14it/s]\n",
      "                   all        540       1728      0.866      0.738      0.844      0.768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.73G     0.4368     0.4629     0.9296         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.13it/s]\n",
      "                   all        540       1728      0.915      0.776      0.864      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.73G     0.4052     0.4012     0.9053          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:37<00:00,  7.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.68it/s]\n",
      "                   all        540       1728      0.903      0.791      0.855      0.794\n",
      "\n",
      "10 epochs completed in 0.320 hours.\n",
      "Optimizer stripped from runs/detect/train76/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train76/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train76/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.38it/s]\n",
      "                   all        540       1728      0.915      0.776      0.864      0.797\n",
      "        Action Figures        540         38      0.877          1      0.985      0.906\n",
      "                   Bag        540         54      0.963      0.976      0.983      0.963\n",
      "Bottles and Cans and Cups        540         40      0.938        0.6      0.672      0.631\n",
      "        Consumer Goods        540        457      0.894      0.906      0.962      0.921\n",
      "              Keyboard        540         15      0.792      0.256      0.469      0.336\n",
      "                 Legos        540         12          1      0.553      0.895      0.788\n",
      "           Media Cases        540         18      0.935      0.722      0.801      0.752\n",
      "                 Mouse        540         12      0.921      0.967      0.989      0.907\n",
      "                  None        540        374      0.901      0.834      0.884       0.84\n",
      "                  Shoe        540        495      0.929      0.834       0.91       0.84\n",
      "                  Toys        540        213      0.916      0.883       0.95      0.883\n",
      "Speed: 0.2ms preprocess, 20.5ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train76\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.01, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train77, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train77\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train77', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train77/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train77\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.15G      3.615      98.48      3.384         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [02:09<00:00,  5.55it/s] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.86it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10         3G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.83it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.02G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.83it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.03G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.90it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.02G        nan        nan        nan          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.81it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.99G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.96it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.03G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.86it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.02G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.03it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      3.01G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.95it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.02G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.00it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "10 epochs completed in 0.341 hours.\n",
      "Optimizer stripped from runs/detect/train77/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train77/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train77/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.61it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 20.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train77\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.01, optimizer: RMSProp\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train78, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train78\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train78', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train78/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train78\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.99G      3.087      4.388      3.187         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:40<00:00,  7.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:20<00:00,  6.67it/s]\n",
      "                   all        540       1728    0.00248     0.0781    0.00213   0.000436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10         3G      3.073      4.093      3.142          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:15<00:00,  8.68it/s]\n",
      "                   all        540       1728     0.0012        0.1   0.000951   0.000306\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.01G      3.072      4.092      3.143         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:14<00:00,  9.47it/s]\n",
      "                   all        540       1728     0.0023      0.139    0.00399   0.000817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.04G      3.029      4.025      3.146          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.24it/s]\n",
      "                   all        540       1728    0.00505     0.0809    0.00345    0.00112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.02G        2.9      3.949      3.054          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.09it/s]\n",
      "                   all        540       1728    0.00505     0.0809    0.00345    0.00112\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10         3G       2.76      3.839      3.042          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.50it/s]\n",
      "                   all        540       1728    0.00325     0.0118    0.00174   0.000424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10         3G      2.661      3.825      2.993          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.89it/s]\n",
      "                   all        540       1728    0.00399    0.00219    0.00208   0.000721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10         3G      2.526      3.674      2.882          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.97it/s]\n",
      "                   all        540       1728    0.00399    0.00219    0.00208   0.000721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10         3G      2.472      3.614      2.826         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.12it/s]\n",
      "                   all        540       1728    0.00399    0.00219    0.00208   0.000721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10         3G      2.436      3.556      2.771          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.83it/s]\n",
      "                   all        540       1728    0.00399    0.00219    0.00208   0.000721\n",
      "\n",
      "10 epochs completed in 0.325 hours.\n",
      "Optimizer stripped from runs/detect/train78/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train78/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train78/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.83it/s]\n",
      "                   all        540       1728    0.00399    0.00219    0.00208   0.000721\n",
      "        Action Figures        540         38          0          0          0          0\n",
      "                   Bag        540         54          0          0          0          0\n",
      "Bottles and Cans and Cups        540         40          0          0          0          0\n",
      "        Consumer Goods        540        457          0          0          0          0\n",
      "              Keyboard        540         15          0          0          0          0\n",
      "                 Legos        540         12          0          0          0          0\n",
      "           Media Cases        540         18          0          0          0          0\n",
      "                 Mouse        540         12          0          0          0          0\n",
      "                  None        540        374     0.0439     0.0241     0.0229    0.00793\n",
      "                  Shoe        540        495          0          0          0          0\n",
      "                  Toys        540        213          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 20.2ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train78\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.1, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train79, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train79\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train79', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train79/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train79\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.74G      1.152      3.216      1.414         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.26it/s]\n",
      "                   all        540       1728       0.38    0.00471    0.00318    0.00162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.76G      2.034      3.562      2.051          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:37<00:00,  7.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.05it/s]\n",
      "                   all        540       1728      0.388     0.0361     0.0159    0.00776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.76G      2.029      3.442      2.031         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.93it/s]\n",
      "                   all        540       1728      0.186     0.0632    0.00828    0.00415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      2.72G      1.811      4.103      1.852          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.04it/s]\n",
      "                   all        540       1728      0.509     0.0981     0.0455     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.73G      1.644      2.783      1.724          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.78it/s]\n",
      "                   all        540       1728      0.403       0.14     0.0563     0.0343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.76G      1.456      2.525      1.575          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.25it/s]\n",
      "                   all        540       1728      0.444      0.145     0.0919     0.0638\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.72G      1.352      2.333      1.497          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.34it/s]\n",
      "                   all        540       1728      0.271      0.188      0.124     0.0841\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.75G       1.24      2.202       1.43          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.14it/s]\n",
      "                   all        540       1728      0.569      0.123      0.106     0.0746\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      2.72G      1.146      2.059      1.354         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00, 10.05it/s]\n",
      "                   all        540       1728       0.46      0.288       0.17      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.72G      1.081      1.973      1.318          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:37<00:00,  7.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.83it/s]\n",
      "                   all        540       1728      0.377      0.268      0.188      0.145\n",
      "\n",
      "10 epochs completed in 0.315 hours.\n",
      "Optimizer stripped from runs/detect/train79/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train79/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train79/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.55it/s]\n",
      "                   all        540       1728      0.377      0.268      0.188      0.145\n",
      "        Action Figures        540         38     0.0808     0.0789     0.0328     0.0248\n",
      "                   Bag        540         54      0.144      0.259      0.214      0.193\n",
      "Bottles and Cans and Cups        540         40     0.0536      0.075     0.0462     0.0288\n",
      "        Consumer Goods        540        457      0.203      0.683      0.298      0.241\n",
      "              Keyboard        540         15          1          0          0          0\n",
      "                 Legos        540         12      0.873      0.167        0.4      0.294\n",
      "           Media Cases        540         18          1          0      0.051     0.0407\n",
      "                 Mouse        540         12          0          0     0.0053    0.00451\n",
      "                  None        540        374      0.229      0.548      0.303      0.238\n",
      "                  Shoe        540        495      0.347      0.661      0.424      0.326\n",
      "                  Toys        540        213      0.219      0.479      0.297      0.201\n",
      "Speed: 0.2ms preprocess, 20.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train79\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.1, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train80, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train80\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train80', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train80/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train80\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      2.98G        nan        nan        nan         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.98it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.02G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.01it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.01G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.76it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10         3G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.99it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.01G        nan        nan        nan          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.98it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      3.01G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.94it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.03G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.83it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.01G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.91it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      3.01G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.01it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.04G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.04it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "10 epochs completed in 0.316 hours.\n",
      "Optimizer stripped from runs/detect/train80/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train80/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train80/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.92it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 20.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train80\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 0.1, optimizer: RMSProp\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train81, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train81\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train81', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train81/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train81\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      3.04G      3.432      72.15      4.133         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.06it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.02G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.62it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      3.02G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.72it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      3.06G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.54it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      3.07G        nan        nan        nan          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.59it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.00it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      3.06G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.00it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.02G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.05it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.06G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.67it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      3.05G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:35<00:00,  7.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.00it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.06G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.94it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "10 epochs completed in 0.325 hours.\n",
      "Optimizer stripped from runs/detect/train81/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train81/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train81/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.96it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "Speed: 0.3ms preprocess, 20.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train81\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 1, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train82, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train82\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train82', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train82/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train82\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.58G      3.552      45.71      3.246         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:39<00:00,  7.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:13<00:00,  9.77it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      2.72G      2.903       1026      2.767          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.12it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.72G          0  1.089e-07          0         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.04it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10       2.7G    0.09271       1441     0.1963          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:33<00:00,  7.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.90it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      2.72G          0  1.231e-05          0          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:33<00:00,  7.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.11it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      2.75G          0  8.278e-11          0          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.15it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      2.71G          0  1.656e-10          0          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.09it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      2.71G          0          0          0          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.75it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.06it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10       2.7G          0          0          0         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.05it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      2.71G          0  1.656e-10          0          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:32<00:00,  7.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.23it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "\n",
      "10 epochs completed in 0.308 hours.\n",
      "Optimizer stripped from runs/detect/train82/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train82/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train82/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.99it/s]\n",
      "                   all        540       1728      0.182    0.00617   0.000175   5.55e-05\n",
      "        Action Figures        540         38          0          0          0          0\n",
      "                   Bag        540         54          0          0          0          0\n",
      "Bottles and Cans and Cups        540         40          0          0          0          0\n",
      "        Consumer Goods        540        457    0.00269     0.0678    0.00167   0.000543\n",
      "              Keyboard        540         15          0          0          0          0\n",
      "                 Legos        540         12          0          0          0          0\n",
      "           Media Cases        540         18          0          0          0          0\n",
      "                 Mouse        540         12          0          0          0          0\n",
      "                  None        540        374          1          0          0          0\n",
      "                  Shoe        540        495          0          0          0          0\n",
      "                  Toys        540        213          1          0   0.000261   6.84e-05\n",
      "Speed: 0.2ms preprocess, 19.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train82\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 1, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=2, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train83, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=1, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train83\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train83', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train83/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=1, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train83\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      3.01G        nan        nan        nan         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:36<00:00,  7.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.13it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      3.02G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.99it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      2.99G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:33<00:00,  7.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.99it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10         3G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.07it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10         3G        nan        nan        nan          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.64it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.04it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10         3G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.62it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      3.04G        nan        nan        nan          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.62it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.74it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      3.03G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.74it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10         3G        nan        nan        nan         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.60it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 11.07it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      3.04G        nan        nan        nan          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 720/720 [01:34<00:00,  7.65it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:12<00:00, 10.94it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "\n",
      "10 epochs completed in 0.326 hours.\n",
      "Optimizer stripped from runs/detect/train83/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train83/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train83/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135/135 [00:11<00:00, 11.37it/s]\n",
      "                   all        540       1728          0          0          0          0\n",
      "Speed: 0.2ms preprocess, 21.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train83\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 2, learning rate: 1, optimizer: RMSProp\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train84, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train84\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train84', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train84/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train84\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.41G     0.8397      2.159      1.269         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:25<00:00,  4.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.83it/s]\n",
      "                   all        540       1728      0.652      0.237       0.23      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.56G     0.9056      1.915      1.321          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.85it/s]\n",
      "                   all        540       1728      0.646      0.257      0.241      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.54G     0.9404      1.871      1.343         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.82it/s]\n",
      "                   all        540       1728      0.527      0.264      0.234      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.57G     0.8525      1.675      1.276         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.86it/s]\n",
      "                   all        540       1728      0.635      0.326      0.328      0.272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.47G     0.7731      1.538      1.212          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.84it/s]\n",
      "                   all        540       1728       0.58      0.415      0.404      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.56G     0.7109      1.384      1.154          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.75it/s]\n",
      "                   all        540       1728      0.555      0.419      0.466      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.56G     0.6371      1.187      1.101         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.77it/s]\n",
      "                   all        540       1728      0.815      0.387      0.473      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.57G      0.597       1.06      1.082         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.87it/s]\n",
      "                   all        540       1728      0.778      0.483      0.571      0.516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.48G      0.558     0.9282      1.049         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.84it/s]\n",
      "                   all        540       1728       0.59      0.622      0.607      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.55G     0.5122     0.8163      1.011         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:22<00:00,  4.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.74it/s]\n",
      "                   all        540       1728      0.764      0.569      0.642      0.584\n",
      "\n",
      "10 epochs completed in 0.302 hours.\n",
      "Optimizer stripped from runs/detect/train84/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train84/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train84/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.64it/s]\n",
      "                   all        540       1728      0.766      0.573      0.642      0.585\n",
      "        Action Figures        540         38      0.526      0.895      0.853      0.777\n",
      "                   Bag        540         54      0.795      0.852      0.848      0.812\n",
      "Bottles and Cans and Cups        540         40      0.495     0.0983      0.219      0.211\n",
      "        Consumer Goods        540        457      0.876      0.792      0.899      0.846\n",
      "              Keyboard        540         15          1          0     0.0145    0.00815\n",
      "                 Legos        540         12      0.913       0.88      0.936      0.763\n",
      "           Media Cases        540         18          1          0      0.247      0.232\n",
      "                 Mouse        540         12      0.615        0.5      0.568      0.502\n",
      "                  None        540        374      0.645      0.781      0.797      0.739\n",
      "                  Shoe        540        495      0.783      0.859      0.886      0.825\n",
      "                  Toys        540        213      0.776      0.651      0.797      0.714\n",
      "Speed: 0.2ms preprocess, 18.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train84\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 4, learning rate: 0.001, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train85, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train85\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train85', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train85/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train85\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.06G      0.622      3.365      1.092         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:26<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.62it/s]\n",
      "                   all        540       1728      0.192      0.247      0.198      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.25G     0.4872       1.94      1.005          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:25<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.68it/s]\n",
      "                   all        540       1728      0.792      0.407      0.462      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.25G     0.4427      1.447     0.9745         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728      0.863       0.49      0.586      0.561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.25G     0.3926      1.054     0.9332         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.74it/s]\n",
      "                   all        540       1728      0.842      0.651      0.749      0.718\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.15G     0.3721     0.8091      0.914          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728      0.843      0.718      0.824       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.27G     0.3507     0.6374     0.8898          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.872      0.824      0.873      0.828\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.26G      0.336     0.5362     0.8784         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.878      0.814      0.884      0.848\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.26G     0.3249     0.4777     0.8749         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.74it/s]\n",
      "                   all        540       1728      0.878      0.848      0.891      0.847\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.27G      0.323     0.4389     0.8673         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728        0.9      0.844      0.893      0.853\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.26G     0.3163     0.4169     0.8671         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.75it/s]\n",
      "                   all        540       1728       0.95      0.841      0.912      0.866\n",
      "\n",
      "10 epochs completed in 0.283 hours.\n",
      "Optimizer stripped from runs/detect/train85/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train85/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train85/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.67it/s]\n",
      "                   all        540       1728       0.95      0.841      0.912      0.866\n",
      "        Action Figures        540         38      0.893          1      0.994       0.98\n",
      "                   Bag        540         54      0.969      0.944      0.979      0.962\n",
      "Bottles and Cans and Cups        540         40      0.968      0.747      0.813      0.802\n",
      "        Consumer Goods        540        457       0.91      0.934      0.975      0.943\n",
      "              Keyboard        540         15          1       0.15      0.533      0.381\n",
      "                 Legos        540         12          1      0.992      0.995      0.902\n",
      "           Media Cases        540         18      0.976      0.833      0.914      0.861\n",
      "                 Mouse        540         12      0.948          1      0.995      0.981\n",
      "                  None        540        374      0.897      0.853      0.913      0.863\n",
      "                  Shoe        540        495      0.971      0.877      0.952      0.915\n",
      "                  Toys        540        213      0.921       0.92      0.966      0.935\n",
      "Speed: 0.2ms preprocess, 18.8ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train85\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 4, learning rate: 0.001, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train86, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train86\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train86', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train86/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.001, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train86\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.29G      3.023      4.413      3.376         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:27<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.48it/s]\n",
      "                   all        540       1728    0.00092     0.0469   0.000588   0.000167\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.53G      2.838      3.833      2.874          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:25<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:13<00:00,  5.22it/s]\n",
      "                   all        540       1728    0.00568      0.094    0.00663    0.00195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.54G      2.751      3.746      2.756         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.77it/s]\n",
      "                   all        540       1728    0.00153     0.0498    0.00105    0.00034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.54G      2.635      3.638      2.602         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.47it/s]\n",
      "                   all        540       1728      0.386     0.0521     0.0117    0.00316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.54G      2.648      3.835      2.608          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:15<00:00,  4.40it/s]\n",
      "                   all        540       1728      0.297     0.0409     0.0281     0.0109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.54G      2.522       3.53      2.499          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:13<00:00,  5.11it/s]\n",
      "                   all        540       1728      0.475     0.0287     0.0324     0.0127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.54G      2.407       3.45      2.417         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728      0.513      0.057     0.0401     0.0117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.55G      2.342      3.368      2.352         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.70it/s]\n",
      "                   all        540       1728    0.00461      0.316     0.0233    0.00887\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.47G      2.288      3.313      2.305         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.75it/s]\n",
      "                   all        540       1728       0.22      0.163     0.0495     0.0197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.55G       2.19      3.205      2.224         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.418     0.0948     0.0413     0.0196\n",
      "\n",
      "10 epochs completed in 0.283 hours.\n",
      "Optimizer stripped from runs/detect/train86/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train86/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train86/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.316      0.146     0.0495     0.0197\n",
      "        Action Figures        540         38      0.124      0.342      0.239      0.108\n",
      "                   Bag        540         54     0.0329      0.148     0.0321     0.0134\n",
      "Bottles and Cans and Cups        540         40          0          0    0.00542    0.00148\n",
      "        Consumer Goods        540        457      0.127      0.346     0.0782     0.0288\n",
      "              Keyboard        540         15          0          0          0          0\n",
      "                 Legos        540         12          1          0    0.00312   0.000769\n",
      "           Media Cases        540         18          1          0          0          0\n",
      "                 Mouse        540         12          1          0          0          0\n",
      "                  None        540        374     0.0346      0.251     0.0333     0.0135\n",
      "                  Shoe        540        495      0.065      0.291     0.0592     0.0215\n",
      "                  Toys        540        213     0.0976       0.23     0.0952     0.0293\n",
      "Speed: 0.2ms preprocess, 19.0ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train86\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 4, learning rate: 0.001, optimizer: RMSProp\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train87, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train87\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train87', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train87/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train87\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.33G      1.756      3.303      2.076         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:27<00:00,  4.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.50it/s]\n",
      "                   all        540       1728      0.587       0.13     0.0792      0.052\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.56G      1.559      2.884      1.877          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:25<00:00,  4.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.64it/s]\n",
      "                   all        540       1728      0.704      0.136     0.0697     0.0455\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.55G      1.449      2.697      1.776         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.67it/s]\n",
      "                   all        540       1728      0.519      0.156     0.0879     0.0555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.57G      1.325      2.517      1.659         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728      0.456      0.208     0.0976     0.0691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.56G      1.273      2.426      1.631          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728      0.726      0.124      0.101      0.071\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.56G      1.185      2.307      1.532          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.70it/s]\n",
      "                   all        540       1728      0.551      0.188      0.125     0.0941\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.55G      1.107      2.166       1.49         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.69it/s]\n",
      "                   all        540       1728      0.579      0.222      0.156       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.57G      1.068      2.117      1.457         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.402      0.267      0.166      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.57G     0.9835      1.997      1.392         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.413      0.234      0.187      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.57G     0.9208      1.881      1.336         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728        0.5      0.271      0.233      0.189\n",
      "\n",
      "10 epochs completed in 0.321 hours.\n",
      "Optimizer stripped from runs/detect/train87/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train87/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train87/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.71it/s]\n",
      "                   all        540       1728        0.5      0.272      0.233      0.189\n",
      "        Action Figures        540         38      0.342      0.132      0.107     0.0886\n",
      "                   Bag        540         54      0.451      0.107      0.223      0.214\n",
      "Bottles and Cans and Cups        540         40          0          0     0.0438     0.0367\n",
      "        Consumer Goods        540        457       0.31      0.722      0.404      0.346\n",
      "              Keyboard        540         15          1          0          0          0\n",
      "                 Legos        540         12          1          0      0.183      0.152\n",
      "           Media Cases        540         18          1          0     0.0271     0.0238\n",
      "                 Mouse        540         12      0.381        0.5      0.367      0.259\n",
      "                  None        540        374      0.332      0.497      0.399      0.324\n",
      "                  Shoe        540        495      0.447       0.65      0.534      0.423\n",
      "                  Toys        540        213      0.233      0.385      0.273      0.214\n",
      "Speed: 0.2ms preprocess, 18.8ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train87\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 4, learning rate: 0.01, optimizer: Adam\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train88, exist_ok=False, pretrained=True, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train88\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train88', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train88/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train88\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.33G     0.5367      2.266      1.036         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:26<00:00,  4.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:12<00:00,  5.65it/s]\n",
      "                   all        540       1728      0.766      0.463      0.579      0.538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      4.27G     0.4512       1.11     0.9556          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:25<00:00,  4.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.808      0.639      0.719      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      4.25G     0.4834     0.9798     0.9718         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.661       0.67       0.74      0.677\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      4.27G     0.5111       0.89     0.9905         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.774      0.731      0.773      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      4.28G     0.5245     0.8039     0.9873          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.738      0.718      0.775      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      4.27G     0.5073     0.6699     0.9564          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.825      0.684      0.789      0.723\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      4.25G     0.4756       0.56     0.9467         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.812      0.772      0.819      0.745\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      4.26G     0.4624     0.4996     0.9413         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.75it/s]\n",
      "                   all        540       1728      0.824      0.776      0.837      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      4.28G     0.4231     0.4172      0.912         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.72it/s]\n",
      "                   all        540       1728      0.883      0.777      0.867       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      4.26G     0.3989     0.3586     0.8994         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:24<00:00,  4.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.73it/s]\n",
      "                   all        540       1728      0.916      0.823      0.894      0.823\n",
      "\n",
      "10 epochs completed in 0.298 hours.\n",
      "Optimizer stripped from runs/detect/train88/weights/last.pt, 136.7MB\n",
      "Optimizer stripped from runs/detect/train88/weights/best.pt, 136.7MB\n",
      "\n",
      "Validating runs/detect/train88/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "Model summary (fused): 268 layers, 68140902 parameters, 0 gradients, 257.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:11<00:00,  5.69it/s]\n",
      "                   all        540       1728      0.917      0.823      0.894      0.822\n",
      "        Action Figures        540         38      0.988      0.974      0.994      0.957\n",
      "                   Bag        540         54      0.935      0.963      0.979      0.965\n",
      "Bottles and Cans and Cups        540         40      0.831      0.736      0.769       0.74\n",
      "        Consumer Goods        540        457      0.886       0.91      0.954      0.901\n",
      "              Keyboard        540         15      0.685      0.133      0.456      0.226\n",
      "                 Legos        540         12          1      0.998      0.995      0.866\n",
      "           Media Cases        540         18          1      0.756      0.926      0.866\n",
      "                 Mouse        540         12      0.956          1      0.995       0.93\n",
      "                  None        540        374      0.918      0.834      0.898      0.839\n",
      "                  Shoe        540        495      0.958      0.869       0.92       0.86\n",
      "                  Toys        540        213      0.926      0.881      0.949       0.89\n",
      "Speed: 0.2ms preprocess, 18.7ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train88\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "model: yolov8x.pt, epochs: 10, batch: 4, learning rate: 0.01, optimizer: SGD\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.218 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.208 ðŸš€ Python-3.8.18 torch-2.0.1+cu117 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 7972MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=data.yaml, epochs=10, patience=50, batch=4, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train89, exist_ok=False, pretrained=True, optimizer=RMSProp, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train89\n",
      "Overriding model.yaml nc=80 with nc=18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8735302  ultralytics.nn.modules.head.Detect           [18, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68169942 parameters, 68169926 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train89', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/train/labels.cache... 1440 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1440/1440 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/datasets/data/test/labels.cache... 540 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540/540 [00:00<?, ?it/s]\n",
      "Plotting labels to runs/detect/train89/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m RMSprop(lr=0.01, momentum=0.937) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train89\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/10      4.29G      3.546      66.05      3.652         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [01:27<00:00,  4.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 68/68 [00:10<00:00,  6.22it/s]\n",
      "                   all        540       1728          0          0          0          0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:337] . unexpected pos 703295296 vs 703295192",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/468: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng and Testing/Testing_and_Training/trainin_testing.ipynb Cell 35\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#X52sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m opt \u001b[39min\u001b[39;00m y_opt:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#X52sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     model \u001b[39m=\u001b[39m YOLO(y_model)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#X52sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     model\u001b[39m.\u001b[39;49mtrain(data \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdata.yaml\u001b[39;49m\u001b[39m\"\u001b[39;49m, epochs \u001b[39m=\u001b[39;49m epoch, batch \u001b[39m=\u001b[39;49m batch, lr0 \u001b[39m=\u001b[39;49m lr0, optimizer \u001b[39m=\u001b[39;49m opt)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#X52sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------------------------------------------------------------------------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/luminatech/Documents/uOttawa/Computer_Vision/Tabinng%20and%20Testing/Testing_and_Training/trainin_testing.ipynb#X52sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodel: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, epochs: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, batch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, learning rate: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, optimizer: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_model, epoch, batch, lr0, opt))\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_ass/lib/python3.8/site-packages/ultralytics/engine/model.py:338\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel\n\u001b[1;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mhub_session \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession  \u001b[39m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 338\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m    339\u001b[0m \u001b[39m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m RANK \u001b[39min\u001b[39;00m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_ass/lib/python3.8/site-packages/ultralytics/engine/trainer.py:190\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ddp_cleanup(\u001b[39mself\u001b[39m, \u001b[39mstr\u001b[39m(file))\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_train(world_size)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_ass/lib/python3.8/site-packages/ultralytics/engine/trainer.py:385\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[39m# Save model\u001b[39;00m\n\u001b[1;32m    384\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mor\u001b[39;00m (epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs):\n\u001b[0;32m--> 385\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_model()\n\u001b[1;32m    386\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks(\u001b[39m'\u001b[39m\u001b[39mon_model_save\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    388\u001b[0m tnow \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_ass/lib/python3.8/site-packages/ultralytics/engine/trainer.py:435\u001b[0m, in \u001b[0;36mBaseTrainer.save_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m torch\u001b[39m.\u001b[39msave(ckpt, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast)\n\u001b[1;32m    434\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_fitness \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness:\n\u001b[0;32m--> 435\u001b[0m     torch\u001b[39m.\u001b[39;49msave(ckpt, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest)\n\u001b[1;32m    436\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_period \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_period \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    437\u001b[0m     torch\u001b[39m.\u001b[39msave(ckpt, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwdir \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv_ass/lib/python3.8/site-packages/ultralytics/utils/patches.py:77\u001b[0m, in \u001b[0;36mtorch_save\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpickle_module\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mpickle_module\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pickle  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[39mreturn\u001b[39;00m _torch_save(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:442\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m--> 442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m opened_file:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 703295296 vs 703295192"
     ]
    }
   ],
   "source": [
    "models = [\"yolov8x.pt\", \"yolov8n.pt\"]\n",
    "y_epochs = [10,20,30]\n",
    "y_batch = [2,4,6]\n",
    "y_learn = [0.001,0.01,0.1]\n",
    "y_opt = [\"Adam\",\"SGD\",\"RMSProp\"]\n",
    "\n",
    "for y_model in models:\n",
    "\n",
    "    for epoch in y_epochs:\n",
    "\n",
    "        for batch in y_batch:\n",
    "\n",
    "            for lr0 in y_learn:\n",
    "\n",
    "                for opt in y_opt:\n",
    "\n",
    "                    model = YOLO(y_model)\n",
    "                    model.train(data = \"data.yaml\", epochs = epoch, batch = batch, lr0 = lr0, optimizer = opt)\n",
    "                    print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                    print(\"model: {}, epochs: {}, batch: {}, learning rate: {}, optimizer: {}\".format(y_model, epoch, batch, lr0, opt))\n",
    "                    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is performing multiple object tracking evaluation using the YOLOv8 model's tracking capabilities and the MOTMetrics library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "model = YOLO(\"runs/detect/train14/weights/best.pt\")\n",
    "i = 0\n",
    "for image in sorted(os.listdir('./datasets/data/test/images')):\n",
    "    img = cv2.imread(os.path.join('./datasets/data/test/images', image))\n",
    "    if i > 17:\n",
    "        results_byte = model.track(img, persist=True, save=True, save_crop=True, project=\"runs/detect\", name=\"inference\", exist_ok=True, tracker='bytetrack.yaml', save_txt = True)\n",
    "    i += 1\n",
    "    if i > 23:\n",
    "        i = 0\n",
    "    model = YOLO(\"runs/detect/train14/weights/best.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0.482274, 0.465779, 0.214265, 0.207781], [1, 1, 0.490777, 0.456626, 0.227856, 0.19846], [2, 1, 0.498438, 0.444312, 0.201918, 0.179492], [3, 1, 0.497055, 0.446929, 0.216776, 0.179446], [4, 1, 0.482835, 0.451588, 0.215653, 0.173287], [5, 1, 0.467578, 0.451564, 0.183371, 0.161832], [6, 1, 0.431422, 0.438638, 0.301905, 0.199226], [7, 1, 0.443282, 0.443592, 0.31274, 0.227706], [8, 1, 0.423571, 0.443033, 0.351003, 0.245764], [9, 1, 0.406313, 0.445539, 0.359482, 0.241453], [10, 1, 0.393336, 0.442515, 0.32518, 0.221246], [11, 1, 0.405306, 0.426554, 0.29502, 0.222233], [12, 1, 0.877736, 0.337628, 0.243937, 0.330563], [13, 2, 0.172073, 0.424649, 0.34175, 0.10597], [14, 1, 0.877629, 0.337439, 0.244244, 0.330098], [15, 2, 0.173433, 0.425714, 0.346866, 0.127861], [16, 1, 0.877304, 0.33769, 0.245094, 0.332088], [17, 2, 0.168021, 0.42447, 0.336041, 0.137977], [18, 1, 0.876195, 0.33796, 0.247325, 0.331272], [19, 2, 0.155407, 0.424547, 0.310326, 0.141997], [20, 1, 0.874943, 0.337553, 0.250114, 0.331476], [21, 2, 0.138307, 0.423231, 0.276614, 0.140807], [22, 1, 0.874462, 0.337555, 0.250988, 0.331982], [23, 2, 0.116734, 0.422595, 0.23154, 0.139511], [24, 1, 0.758678, 0.213546, 0.190202, 0.242297], [25, 2, 0.195226, 0.297145, 0.390285, 0.264551], [26, 3, 0.884106, 0.658442, 0.231787, 0.23293], [27, 1, 0.190417, 0.296475, 0.377652, 0.274708], [28, 2, 0.761122, 0.207004, 0.206401, 0.242523], [29, 3, 0.89782, 0.650544, 0.20436, 0.192884], [30, 1, 0.175074, 0.294493, 0.348247, 0.266943], [31, 2, 0.763233, 0.188166, 0.218493, 0.224823], [32, 1, 0.152573, 0.287663, 0.305145, 0.249785], [33, 2, 0.764566, 0.181617, 0.234893, 0.22565], [34, 1, 0.123329, 0.282448, 0.246593, 0.215651], [35, 2, 0.763332, 0.182686, 0.245538, 0.242567], [36, 3, 0.952923, 0.740344, 0.0941545, 0.127081], [37, 1, 0.110427, 0.280318, 0.220428, 0.244916], [38, 2, 0.763326, 0.173077, 0.255085, 0.237282], [39, 3, 0.763662, 0.17363, 0.255547, 0.242892], [40, 1, 0.506982, 0.504068, 0.418801, 0.336047], [41, 2, 0.0882647, 0.695739, 0.175191, 0.608523], [42, 3, 0.754759, 0.320724, 0.202878, 0.0703936], [43, 4, 0.102312, 0.27262, 0.204625, 0.13908], [44, 5, 0.403586, 0.367659, 0.152362, 0.0854756], [45, 1, 0.752252, 0.318018, 0.200324, 0.0708491], [46, 2, 0.394425, 0.365739, 0.169749, 0.0842895], [47, 3, 0.423549, 0.541483, 0.233598, 0.283161], [48, 4, 0.0887899, 0.708531, 0.173888, 0.582937], [49, 5, 0.100475, 0.268867, 0.200951, 0.150333], [50, 1, 0.747404, 0.316475, 0.194124, 0.0686287], [51, 2, 0.389371, 0.364441, 0.171828, 0.0844791], [52, 3, 0.441224, 0.554905, 0.233498, 0.297595], [53, 4, 0.0966046, 0.263845, 0.193209, 0.161826], [54, 5, 0.489723, 0.550378, 0.33089, 0.308722], [55, 1, 0.384081, 0.362672, 0.174818, 0.0817729], [56, 2, 0.743923, 0.312091, 0.187209, 0.0685322], [57, 3, 0.485326, 0.548254, 0.275656, 0.331818], [58, 4, 0.0914451, 0.26534, 0.182729, 0.165564], [59, 5, 0.0730528, 0.764051, 0.143674, 0.471898], [60, 1, 0.0891112, 0.269636, 0.178222, 0.165277], [61, 2, 0.493386, 0.556526, 0.236323, 0.334557], [62, 3, 0.379739, 0.360214, 0.174917, 0.0805452], [63, 4, 0.740872, 0.310855, 0.178097, 0.0685359], [64, 5, 0.0562392, 0.771452, 0.111712, 0.457096], [65, 1, 0.500308, 0.571598, 0.215453, 0.352142], [66, 2, 0.0892822, 0.274668, 0.178179, 0.160415], [67, 3, 0.374753, 0.357515, 0.175687, 0.0778648], [68, 4, 0.737562, 0.308296, 0.165863, 0.0704308], [69, 5, 0.0347194, 0.780398, 0.0692839, 0.439203], [70, 1, 0.553974, 0.837834, 0.396433, 0.316251], [71, 2, 0.453313, 0.11826, 0.276805, 0.236519], [72, 3, 0.216705, 0.661185, 0.396439, 0.236377], [73, 4, 0.863932, 0.287266, 0.272135, 0.230001], [74, 5, 0.44686, 0.314118, 0.217615, 0.294522], [75, 6, 0.0336706, 0.822181, 0.0673413, 0.160983], [76, 1, 0.578775, 0.841805, 0.395843, 0.308784], [77, 2, 0.460652, 0.112478, 0.244341, 0.224956], [78, 3, 0.210353, 0.665745, 0.39775, 0.234215], [79, 4, 0.870743, 0.282598, 0.258515, 0.228604], [80, 5, 0.458964, 0.322174, 0.229267, 0.306781], [81, 6, 0.0385418, 0.8049, 0.0770835, 0.160874], [82, 7, 0.387052, 0.372057, 0.110804, 0.104737], [83, 1, 0.604661, 0.852305, 0.400895, 0.291526], [84, 2, 0.203622, 0.67011, 0.397065, 0.229139], [85, 3, 0.877353, 0.277677, 0.244054, 0.22618], [86, 4, 0.471245, 0.11053, 0.267681, 0.22106], [87, 5, 0.46635, 0.325959, 0.255621, 0.307797], [88, 1, 0.628096, 0.857474, 0.408376, 0.278231], [89, 2, 0.198835, 0.673008, 0.391303, 0.226162], [90, 3, 0.882294, 0.273131, 0.234271, 0.22398], [91, 4, 0.465881, 0.112119, 0.304352, 0.224238], [92, 5, 0.470685, 0.32914, 0.271984, 0.301805], [93, 6, 0.0345809, 0.774498, 0.0691618, 0.156407], [94, 1, 0.656061, 0.863465, 0.407403, 0.273071], [95, 2, 0.199784, 0.672953, 0.381833, 0.226532], [96, 3, 0.888959, 0.270682, 0.222082, 0.226026], [97, 4, 0.462591, 0.110581, 0.331931, 0.221163], [98, 5, 0.469501, 0.336456, 0.281217, 0.290852], [99, 6, 0.436714, 0.374284, 0.1355, 0.158216], [100, 1, 0.675968, 0.866669, 0.432037, 0.26449], [101, 2, 0.21315, 0.667325, 0.366754, 0.240597], [102, 3, 0.895022, 0.26648, 0.209956, 0.224509], [103, 4, 0.464805, 0.347713, 0.29208, 0.272403], [104, 5, 0.456672, 0.107063, 0.350323, 0.214125], [105, 1, 0.331079, 0.788975, 0.48999, 0.358047], [106, 2, 0.224311, 0.219509, 0.235991, 0.276463], [107, 3, 0.277787, 0.524139, 0.205161, 0.191462], [108, 4, 0.869477, 0.613891, 0.261045, 0.221061], [109, 5, 0.566665, 0.374622, 0.21968, 0.0962608], [110, 1, 0.327205, 0.798281, 0.545907, 0.397341], [111, 2, 0.221792, 0.219495, 0.251122, 0.277806], [112, 3, 0.87767, 0.624887, 0.243524, 0.229713], [113, 4, 0.558297, 0.37519, 0.208604, 0.100073], [114, 5, 0.2883, 0.530678, 0.134833, 0.191974], [115, 1, 0.298219, 0.799254, 0.591624, 0.396806], [116, 2, 0.218443, 0.220277, 0.258296, 0.281611], [117, 3, 0.885887, 0.637996, 0.228225, 0.242057], [118, 4, 0.268286, 0.526303, 0.225154, 0.169181], [119, 5, 0.551021, 0.374182, 0.194787, 0.10318], [120, 1, 0.279117, 0.792233, 0.558234, 0.358542], [121, 2, 0.218592, 0.22098, 0.248837, 0.282202], [122, 3, 0.545204, 0.372543, 0.175845, 0.106596], [123, 4, 0.238125, 0.534436, 0.306742, 0.158156], [124, 5, 0.895534, 0.665879, 0.208932, 0.279776], [125, 1, 0.292448, 0.782351, 0.516323, 0.328077], [126, 2, 0.228243, 0.223256, 0.230193, 0.28179], [127, 3, 0.538991, 0.370981, 0.155107, 0.110159], [128, 4, 0.208512, 0.53659, 0.359123, 0.129196], [129, 5, 0.902589, 0.647903, 0.194109, 0.228614], [130, 1, 0.223807, 0.221314, 0.252167, 0.282793], [131, 2, 0.32696, 0.802002, 0.53772, 0.394734], [132, 3, 0.183234, 0.542948, 0.366468, 0.121433], [133, 4, 0.534541, 0.367067, 0.134912, 0.107174], [134, 5, 0.913722, 0.639571, 0.172287, 0.190274], [135, 1, 0.228805, 0.866081, 0.456124, 0.267838], [136, 2, 0.747413, 0.901619, 0.505173, 0.19609], [137, 3, 0.62676, 0.569039, 0.252247, 0.111915], [138, 4, 0.633167, 0.360723, 0.157228, 0.103148], [139, 5, 0.0580395, 0.390027, 0.116079, 0.319731], [140, 6, 0.930894, 0.473283, 0.138213, 0.176391], [141, 7, 0.162782, 0.318801, 0.207038, 0.192085], [142, 1, 0.220392, 0.873594, 0.440784, 0.249564], [143, 2, 0.62776, 0.576909, 0.241055, 0.103899], [144, 3, 0.945471, 0.464938, 0.109059, 0.162507], [145, 4, 0.77002, 0.920524, 0.459812, 0.158952], [146, 5, 0.643706, 0.358354, 0.139822, 0.104199], [147, 6, 0.0521787, 0.387723, 0.102696, 0.322537], [148, 7, 0.131798, 0.314929, 0.217195, 0.187249], [149, 1, 0.654528, 0.356028, 0.124688, 0.106495], [150, 2, 0.212989, 0.882843, 0.425977, 0.234314], [151, 3, 0.114979, 0.311776, 0.202897, 0.186506], [152, 4, 0.0438321, 0.380556, 0.0876641, 0.316273], [153, 5, 0.802148, 0.943059, 0.393051, 0.113882], [154, 6, 0.620783, 0.589769, 0.24101, 0.128368], [155, 7, 0.957954, 0.463196, 0.0840914, 0.162745], [156, 1, 0.109581, 0.310932, 0.197479, 0.189792], [157, 2, 0.665318, 0.351815, 0.105259, 0.110234], [158, 3, 0.206676, 0.891309, 0.413352, 0.217383], [159, 4, 0.616368, 0.586541, 0.242334, 0.123392], [160, 5, 0.0386609, 0.380601, 0.0773218, 0.329753], [161, 6, 0.877979, 0.965835, 0.244041, 0.0683305], [162, 7, 0.970269, 0.458661, 0.0594629, 0.171878], [163, 8, 0.0385588, 0.387081, 0.0771177, 0.346008], [164, 1, 0.109945, 0.307409, 0.211996, 0.186976], [165, 2, 0.192646, 0.900515, 0.385292, 0.198971], [166, 3, 0.675957, 0.347425, 0.0871977, 0.11128], [167, 4, 0.621172, 0.597183, 0.256523, 0.148791], [168, 1, 0.110529, 0.307518, 0.219588, 0.191433], [169, 2, 0.617189, 0.614821, 0.280802, 0.18258], [170, 3, 0.18589, 0.91166, 0.371779, 0.17668], [171, 4, 0.684862, 0.349743, 0.0777647, 0.123706], [172, 1, 0.496756, 0.440086, 0.180104, 0.13721], [173, 1, 0.499509, 0.440331, 0.22659, 0.138575], [174, 1, 0.496468, 0.438404, 0.26577, 0.141109], [175, 1, 0.495667, 0.436223, 0.286372, 0.136841], [176, 1, 0.493055, 0.435702, 0.295039, 0.128978], [177, 1, 0.491589, 0.433119, 0.289267, 0.120663], [178, 1, 0.461131, 0.210814, 0.140146, 0.156378], [179, 2, 0.642801, 0.677974, 0.244807, 0.325814], [180, 3, 0.442337, 0.401766, 0.0784115, 0.139077], [181, 1, 0.659813, 0.683201, 0.279405, 0.320582], [182, 2, 0.456218, 0.202745, 0.14728, 0.150501], [183, 3, 0.432647, 0.397225, 0.0813301, 0.146671], [184, 1, 0.674379, 0.690955, 0.297778, 0.31149], [185, 2, 0.451978, 0.19615, 0.152169, 0.145154], [186, 3, 0.430275, 0.401289, 0.0796011, 0.134788], [187, 1, 0.694221, 0.693064, 0.308991, 0.29693], [188, 2, 0.443754, 0.192736, 0.153568, 0.148338], [189, 3, 0.426798, 0.383421, 0.0811546, 0.164861], [190, 1, 0.717832, 0.69976, 0.309186, 0.270742], [191, 2, 0.438073, 0.18506, 0.161239, 0.139065], [192, 3, 0.422481, 0.388455, 0.0866376, 0.143335], [193, 1, 0.728464, 0.708372, 0.324815, 0.248395], [194, 2, 0.433226, 0.178768, 0.168769, 0.131902], [195, 3, 0.426719, 0.385423, 0.0848978, 0.142182], [196, 1, 0.514529, 0.0999619, 0.278352, 0.183989], [197, 2, 0.601672, 0.4562, 0.206342, 0.149706], [198, 3, 0.193326, 0.656835, 0.271811, 0.166068], [199, 4, 0.643567, 0.867462, 0.122073, 0.265075], [200, 5, 0.335496, 0.298176, 0.149276, 0.0767403], [201, 6, 0.0940169, 0.209273, 0.188034, 0.213692], [202, 7, 0.0938426, 0.210147, 0.187685, 0.215061], [203, 1, 0.513155, 0.0846195, 0.277827, 0.169239], [204, 2, 0.177999, 0.660151, 0.275758, 0.196281], [205, 3, 0.658912, 0.870009, 0.16783, 0.259982], [206, 4, 0.601998, 0.445345, 0.204986, 0.135867], [207, 5, 0.32335, 0.282866, 0.147731, 0.0765899], [208, 1, 0.51465, 0.0734222, 0.275296, 0.146777], [209, 2, 0.603126, 0.438518, 0.206102, 0.125344], [210, 3, 0.16431, 0.660429, 0.278547, 0.217891], [211, 4, 0.667836, 0.875225, 0.210593, 0.24955], [212, 5, 0.308656, 0.268569, 0.141816, 0.0824108], [213, 1, 0.603412, 0.428646, 0.207163, 0.143759], [214, 2, 0.517443, 0.0628565, 0.264824, 0.125376], [215, 3, 0.149455, 0.661213, 0.273094, 0.246998], [216, 4, 0.663268, 0.881913, 0.273916, 0.234357], [217, 5, 0.295878, 0.25426, 0.138308, 0.0879663], [218, 1, 0.519327, 0.0529141, 0.253143, 0.105828], [219, 2, 0.603312, 0.418667, 0.208037, 0.158181], [220, 3, 0.13464, 0.661745, 0.262026, 0.262723], [221, 4, 0.685336, 0.891346, 0.291811, 0.217309], [222, 5, 0.282191, 0.240479, 0.129146, 0.0929986], [223, 6, 0.0385948, 0.153361, 0.0771896, 0.172098], [224, 1, 0.604289, 0.409805, 0.205503, 0.174887], [225, 2, 0.122678, 0.658429, 0.24453, 0.280578], [226, 3, 0.519043, 0.0431293, 0.250711, 0.0851242], [227, 4, 0.696117, 0.903378, 0.333512, 0.193244], [228, 5, 0.271176, 0.222422, 0.126937, 0.0950356], [229, 1, 0.174498, 0.745501, 0.348996, 0.251393], [230, 2, 0.251554, 0.274899, 0.267693, 0.214683], [231, 3, 0.472252, 0.5603, 0.217289, 0.209172], [232, 4, 0.47555, 0.289782, 0.173083, 0.207829], [233, 1, 0.171982, 0.761599, 0.343963, 0.259485], [234, 2, 0.452132, 0.558669, 0.240421, 0.176308], [235, 3, 0.4753, 0.278131, 0.171679, 0.206061], [236, 4, 0.236343, 0.279721, 0.279065, 0.197948], [237, 1, 0.169568, 0.779893, 0.339137, 0.26874], [238, 2, 0.432787, 0.56135, 0.261727, 0.144156], [239, 3, 0.220439, 0.282679, 0.285418, 0.180716], [240, 4, 0.474297, 0.266194, 0.170043, 0.204494], [241, 1, 0.166286, 0.799794, 0.332572, 0.27904], [242, 2, 0.410857, 0.561796, 0.273405, 0.109157], [243, 3, 0.204927, 0.287973, 0.296922, 0.165119], [244, 4, 0.473925, 0.254162, 0.169091, 0.204288], [245, 1, 0.162433, 0.81527, 0.324865, 0.300158], [246, 2, 0.18824, 0.290099, 0.302386, 0.148841], [247, 3, 0.38849, 0.565046, 0.278485, 0.114424], [248, 4, 0.473503, 0.242421, 0.166084, 0.203266], [249, 1, 0.157886, 0.829147, 0.315772, 0.323765], [250, 2, 0.172878, 0.293818, 0.305912, 0.131594], [251, 3, 0.36571, 0.562834, 0.276173, 0.148025], [252, 4, 0.473717, 0.231917, 0.163102, 0.203477], [253, 1, 0.0921773, 0.265032, 0.184355, 0.292648], [254, 2, 0.414303, 0.243236, 0.232501, 0.218471], [255, 3, 0.348407, 0.575515, 0.344006, 0.135234], [256, 4, 0.10476, 0.480241, 0.19896, 0.103939], [257, 1, 0.0828169, 0.260372, 0.163554, 0.294549], [258, 2, 0.404502, 0.236934, 0.230249, 0.215146], [259, 3, 0.335897, 0.59659, 0.354368, 0.122241], [260, 4, 0.0866996, 0.479527, 0.17077, 0.0909531], [261, 5, 0.490005, 0.418372, 0.224043, 0.20412], [262, 1, 0.0733815, 0.255297, 0.144679, 0.295742], [263, 2, 0.396822, 0.233148, 0.211437, 0.215404], [264, 3, 0.320379, 0.615389, 0.367032, 0.0956233], [265, 4, 0.0724564, 0.480659, 0.142792, 0.0908895], [266, 5, 0.481807, 0.408694, 0.244468, 0.202841], [267, 1, 0.39514, 0.231635, 0.194405, 0.219048], [268, 2, 0.30327, 0.61862, 0.379472, 0.095548], [269, 3, 0.0563626, 0.498507, 0.112725, 0.103804], [270, 4, 0.47273, 0.39459, 0.256524, 0.192284], [271, 1, 0.288394, 0.630628, 0.391851, 0.104048], [272, 2, 0.375639, 0.228708, 0.218737, 0.217703], [273, 3, 0.039453, 0.515203, 0.078906, 0.136519], [274, 4, 0.055225, 0.248089, 0.10756, 0.300156], [275, 5, 0.465051, 0.383753, 0.26831, 0.187431], [276, 6, 0.0548298, 0.250235, 0.109439, 0.312232], [277, 1, 0.355675, 0.223018, 0.226682, 0.2174], [278, 2, 0.270689, 0.638609, 0.400986, 0.117066], [279, 3, 0.457988, 0.370549, 0.272136, 0.177202], [280, 4, 0.460243, 0.370176, 0.272206, 0.178272], [281, 1, 0.192081, 0.491504, 0.179415, 0.136759], [282, 2, 0.540048, 0.506994, 0.144211, 0.0969965], [283, 3, 0.387214, 0.327666, 0.135211, 0.0764794], [284, 1, 0.183136, 0.492762, 0.178491, 0.137826], [285, 2, 0.379622, 0.322795, 0.125417, 0.0773679], [286, 3, 0.541103, 0.509342, 0.129603, 0.110425], [287, 1, 0.173582, 0.495052, 0.17616, 0.137847], [288, 2, 0.542953, 0.51096, 0.105085, 0.120343], [289, 3, 0.374298, 0.316834, 0.116938, 0.0825436], [290, 1, 0.165839, 0.497234, 0.178462, 0.138449], [291, 2, 0.544614, 0.514119, 0.0832251, 0.129499], [292, 3, 0.36963, 0.309499, 0.117895, 0.0787241], [293, 1, 0.155083, 0.498895, 0.176515, 0.136813], [294, 2, 0.544412, 0.515201, 0.0629842, 0.134165], [295, 3, 0.362856, 0.303249, 0.119989, 0.080373], [296, 1, 0.147701, 0.500468, 0.177311, 0.137238], [297, 2, 0.357244, 0.29781, 0.118644, 0.0770262], [298, 3, 0.549562, 0.518044, 0.0622597, 0.134041], [299, 1, 0.267828, 0.391207, 0.322352, 0.204863], [300, 2, 0.317959, 0.580838, 0.227645, 0.277934], [301, 3, 0.874585, 0.93769, 0.25083, 0.124619], [302, 1, 0.314448, 0.597942, 0.195569, 0.281589], [303, 2, 0.259336, 0.400175, 0.312185, 0.204514], [304, 1, 0.252151, 0.405622, 0.293245, 0.198439], [305, 2, 0.311775, 0.613638, 0.161498, 0.284012], [306, 1, 0.24624, 0.410058, 0.26465, 0.188664], [307, 2, 0.308678, 0.628078, 0.140564, 0.284281], [308, 1, 0.244457, 0.414385, 0.22701, 0.179336], [309, 2, 0.317897, 0.643378, 0.14521, 0.282672], [310, 1, 0.250418, 0.421757, 0.198796, 0.188374], [311, 2, 0.323713, 0.658869, 0.165534, 0.278897], [312, 1, 0.586528, 0.474674, 0.167004, 0.197875], [313, 1, 0.59754, 0.472922, 0.160548, 0.192861], [314, 1, 0.565635, 0.471802, 0.224862, 0.184463], [315, 1, 0.554148, 0.472076, 0.230645, 0.181732], [316, 1, 0.54316, 0.47784, 0.218125, 0.187422], [317, 1, 0.522576, 0.482172, 0.216451, 0.204848], [318, 1, 0.279499, 0.603046, 0.385054, 0.300792], [319, 2, 0.900077, 0.35823, 0.199547, 0.181808], [320, 3, 0.921184, 0.096463, 0.109233, 0.111322], [321, 1, 0.261605, 0.602336, 0.386975, 0.315443], [322, 2, 0.908994, 0.370594, 0.174464, 0.200216], [323, 3, 0.954855, 0.0959959, 0.0902891, 0.11914], [324, 1, 0.243528, 0.599054, 0.372629, 0.314052], [325, 2, 0.918278, 0.382942, 0.147569, 0.210637], [326, 1, 0.225796, 0.59493, 0.338855, 0.298814], [327, 2, 0.936539, 0.387552, 0.122335, 0.235223], [328, 1, 0.211344, 0.587351, 0.28663, 0.285867], [329, 2, 0.933552, 0.396884, 0.132896, 0.238895], [330, 1, 0.20874, 0.586554, 0.253344, 0.315675], [331, 2, 0.927897, 0.408772, 0.144205, 0.247127], [332, 1, 0.878, 0.8165, 0.179389, 0.36642], [333, 2, 0.111459, 0.339135, 0.222917, 0.123859], [334, 3, 0.0976307, 0.528258, 0.115851, 0.194284], [335, 1, 0.886274, 0.828195, 0.227452, 0.34361], [336, 2, 0.102132, 0.307917, 0.204265, 0.124602], [337, 3, 0.0768316, 0.500512, 0.11737, 0.196563], [338, 1, 0.878518, 0.842023, 0.241287, 0.315954], [339, 2, 0.0933577, 0.273295, 0.186715, 0.132365], [340, 1, 0.874357, 0.859436, 0.250106, 0.281127], [341, 2, 0.0852162, 0.238711, 0.170432, 0.1236], [342, 1, 0.870574, 0.880279, 0.258851, 0.237601], [343, 2, 0.0792792, 0.204878, 0.158558, 0.120847], [344, 1, 0.868668, 0.905062, 0.262664, 0.189877], [345, 2, 0.0741999, 0.165938, 0.1484, 0.124689], [346, 1, 0.520759, 0.366546, 0.253893, 0.188268], [347, 2, 0.263033, 0.459991, 0.233334, 0.176359], [348, 3, 0.838596, 0.663198, 0.221751, 0.152186], [349, 4, 0.401552, 0.814856, 0.100762, 0.237727], [350, 5, 0.4978, 0.113256, 0.130636, 0.131744], [351, 6, 0.044503, 0.647241, 0.0890061, 0.273144], [352, 1, 0.25373, 0.453213, 0.233468, 0.169445], [353, 2, 0.511051, 0.100864, 0.139054, 0.127846], [354, 3, 0.851429, 0.681927, 0.227526, 0.154827], [355, 4, 0.518039, 0.360857, 0.260767, 0.169409], [356, 5, 0.372993, 0.8212, 0.0952599, 0.243376], [357, 6, 0.0260472, 0.614316, 0.0520944, 0.225583], [358, 1, 0.247454, 0.445512, 0.2322, 0.156068], [359, 2, 0.51324, 0.356024, 0.266099, 0.153909], [360, 3, 0.865468, 0.703394, 0.233766, 0.164369], [361, 4, 0.351954, 0.830095, 0.119123, 0.243547], [362, 5, 0.524149, 0.0898892, 0.142102, 0.123195], [363, 1, 0.538246, 0.0782752, 0.147678, 0.119949], [364, 2, 0.240792, 0.437202, 0.21894, 0.134539], [365, 3, 0.511815, 0.349933, 0.273306, 0.138992], [366, 4, 0.876884, 0.726233, 0.238945, 0.169006], [367, 5, 0.327552, 0.83575, 0.147173, 0.240693], [368, 1, 0.23628, 0.429042, 0.199113, 0.133385], [369, 2, 0.508375, 0.344952, 0.277851, 0.129913], [370, 3, 0.884299, 0.749312, 0.229396, 0.171709], [371, 4, 0.303075, 0.841198, 0.178491, 0.229596], [372, 5, 0.554063, 0.0673049, 0.153353, 0.117862], [373, 1, 0.280768, 0.84725, 0.210111, 0.216996], [374, 2, 0.889248, 0.774822, 0.221505, 0.175925], [375, 3, 0.231294, 0.42401, 0.206751, 0.145385], [376, 4, 0.505405, 0.341732, 0.280283, 0.125234], [377, 5, 0.570332, 0.0581878, 0.1573, 0.11268], [378, 1, 0.760197, 0.808648, 0.479606, 0.378114], [379, 2, 0.410222, 0.379321, 0.19746, 0.11885], [380, 3, 0.545193, 0.481812, 0.286155, 0.13553], [381, 1, 0.735035, 0.818933, 0.529931, 0.362134], [382, 2, 0.416037, 0.377479, 0.178108, 0.12359], [383, 3, 0.544198, 0.482089, 0.287175, 0.135721], [384, 1, 0.42334, 0.37694, 0.137296, 0.129469], [385, 2, 0.700713, 0.828421, 0.598573, 0.342606], [386, 3, 0.542994, 0.482908, 0.28834, 0.136882], [387, 1, 0.652217, 0.847082, 0.651777, 0.302499], [388, 2, 0.542303, 0.48362, 0.288218, 0.137027], [389, 3, 0.43629, 0.374961, 0.0913031, 0.127743], [390, 1, 0.449185, 0.369428, 0.141581, 0.112589], [391, 2, 0.54051, 0.483766, 0.28908, 0.137201], [392, 3, 0.61945, 0.857332, 0.75272, 0.284657], [393, 1, 0.453259, 0.367506, 0.179958, 0.106631], [394, 2, 0.539547, 0.483912, 0.288442, 0.137682], [395, 3, 0.550051, 0.859568, 0.75316, 0.280863], [396, 1, 0.511178, 0.444256, 0.229787, 0.126309], [397, 1, 0.518823, 0.4443, 0.265587, 0.130613], [398, 1, 0.525122, 0.444419, 0.28566, 0.131188], [399, 1, 0.531845, 0.44471, 0.297282, 0.133844], [400, 1, 0.538598, 0.445035, 0.298158, 0.135099], [401, 1, 0.543672, 0.44535, 0.289099, 0.132877], [402, 1, 0.399899, 0.432753, 0.272105, 0.211917], [403, 1, 0.395496, 0.432121, 0.280006, 0.209998], [404, 1, 0.390557, 0.430581, 0.275341, 0.20852], [405, 1, 0.3811, 0.430262, 0.256117, 0.207312], [406, 1, 0.385763, 0.427714, 0.261569, 0.208244], [407, 1, 0.391378, 0.424705, 0.285018, 0.211263]]\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "\n",
    "f = open(os.path.join('./runs/detect/inference/labels/image0.txt'),'r')\n",
    "\n",
    "frame = 0\n",
    "\n",
    "pred_mot = []\n",
    "\n",
    "for line in f:\n",
    "\n",
    "    line = line.strip()\n",
    "    line = line.split()\n",
    "    \n",
    "    pred_mot.append([frame, int(line[5]), float(line[1]), float(line[2]), float(line[3]), float(line[4])])\n",
    "    \n",
    "    frame += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "for pred, gt in zip(pred_mot, gt_mot):\n",
    "\n",
    "    pred = np.array(pred)\n",
    "    pred = pred[:, np.newaxis]\n",
    "    pred = np.ravel(pred)\n",
    "    \n",
    "    gt = np.array(gt)\n",
    "    gt = gt[:, np.newaxis]\n",
    "    gt = np.ravel(gt)\n",
    "    \n",
    "    print(gt[2:])\n",
    "    \n",
    "    C = mm.distances.iou_matrix(gt[2:], pred[2:], max_iou=0.5)\n",
    "\n",
    "    gt = np.array(gt)\n",
    "    pred = np.array(pred)\n",
    "\n",
    "    acc.update(gt[:,0].astype('int').tolist(), \\\n",
    "                  pred[:,0].astype('int').tolist(), C)\n",
    "\n",
    "mh = mm.metrics.create()\n",
    "\n",
    "summary = mh.compute(acc, metrics=['num_frames', 'idf1', 'idp', 'idr', \\\n",
    "                                     'recall', 'precision', 'num_objects', \\\n",
    "                                     'mostly_tracked', 'partially_tracked', \\\n",
    "                                     'mostly_lost', 'num_false_positives', \\\n",
    "                                     'num_misses', 'num_switches', \\\n",
    "                                     'num_fragmentations', 'mota', 'motp' \\\n",
    "                                    ], \\\n",
    "                      name='acc')\n",
    "\n",
    "strsummary = mm.io.render_summary(\n",
    "    summary,\n",
    "    #formatters={'mota' : '{:.2%}'.format},\n",
    "    namemap={'idf1': 'IDF1', 'idp': 'IDP', 'idr': 'IDR', 'recall': 'Rcll', \\\n",
    "             'precision': 'Prcn', 'num_objects': 'GT', \\\n",
    "             'mostly_tracked' : 'MT', 'partially_tracked': 'PT', \\\n",
    "             'mostly_lost' : 'ML', 'num_false_positives': 'FP', \\\n",
    "             'num_misses': 'FN', 'num_switches' : 'IDsw', \\\n",
    "             'num_fragmentations' : 'FM', 'mota': 'MOTA', 'motp' : 'MOTP',  \\\n",
    "            }\n",
    ")\n",
    "\n",
    "print(strsummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
